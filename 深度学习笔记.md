1. æ·±åº¦å­¦ä¹ ç®€ä»‹

   äººå·¥ç¥ç»ç½‘ç»œç§°ä¸ºäººå·¥æ™ºèƒ½çš„è¿æ¥å­¦æ´¾

   1. æ„ŸçŸ¥æœºåˆ°äººå·¥ç¥ç»ç½‘ç»œ

      + 1957å¹´ å¼—å…°å…‹æå‡ºæ„ŸçŸ¥æœºæ¨¡å‹ï¼ˆä¸æ˜¯ç›´æ¥ä»åŠŸèƒ½çš„è§’åº¦è€Œæ˜¯é€šè¿‡ç»“æ„æ¨¡æ‹Ÿï¼‰
      + 1969å¹´ æå‡ºæ„ŸçŸ¥æœºæ¨¡å‹è¿XORé—®é¢˜æ— æ³•è§£å‡ºï¼Œäººå·¥ç¥ç»ç½‘ç»œè¢«æ‰“å…¥ç½‘ç»œ
      + è¾›é¡¿å‘å±•äº†äººå·¥ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­æ³•ï¼Œä»è€Œå¯ä»¥æ„é€ ä¸¤å±‚ä»¥ä¸Šç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”å¯ä»¥æœ‰æ•ˆè¿›è¡Œå­¦ä¹ ä¸è®­ç»ƒï¼Œä¸¤å±‚ä»¥ä¸Šç¥ç»ç½‘ç»œå¯ä»¥å¾ˆè½»æ¾è§£å†³XORé—®é¢˜ã€‚
      + å—é™äºå½“æ—¶çš„è®¡ç®—èƒ½åŠ›ï¼Œå¦ä¸€æ–¹é¢ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡çš„æ•°æ®ï¼Œç¥ç»ç½‘ç»œæœ¬èº«å°±æ˜¯ä¸€ä¸ªé»‘ç®±ï¼Œè°ä¹Ÿä¸æ•¢ä¿è¯æ·±åº¦ç¥ç»ç½‘ç»œåœ¨æ·±åº¦è¿™ä¸ªæ–¹å‘ä¸Šå°±èƒ½å¤Ÿå–å¾—æ›´å¥½çš„ç»“æœå’Œç²¾åº¦ã€‚äººå·¥ç¥ç»ç½‘ç»œå¹¶æ²¡æœ‰ç»§ç»­æ²¿ç€æ·±åº¦çš„æ–¹å‘å‘å±•ä¸‹å»ã€‚
      + å­¦æœ¯ç•Œçš„ç„¦ç‚¹æœå‘äº†å¦ä¸€ä¸ªå‘å±•æ–¹å‘ï¼šå¯»æ‰¾ç¥ç»ç½‘ç»œçš„åŸºç¡€ç†è®ºã€‚åœ¨å¼—æ‹‰åŸºç±³å°”å’Œäºšå†å…‹å¡æ¨è¿›ä¸‹ï¼Œç»Ÿè®¡å­¦ä¹ ç†è®ºè“¬å‹ƒå‘å±•ï¼Œå¥ å®šäº†æ¨¡å¼è¯†åˆ«çš„æ•°å­¦åŸºç¡€ï¼Œåˆ›é€ å‡ºäº†æ”¯æŒå‘é‡æœºè¿™ç§æå…¶å®ç”¨ç®€å•çš„å·¥å…·ã€‚ä¸ä¼ ç»Ÿç¥ç»ç½‘ç»œé€šè¿‡åŠ æ·±ç½‘ç»œæ¥æå‡ç²¾åº¦ç›¸åï¼Œæ”¯æŒå‘é‡æœºçš„è§£å†³æ–¹æ¡ˆæ˜¯å°†æ•°æ®çš„ç»´åº¦æå‡ï¼Œåœ¨é«˜ç»´ç§å¯»æ‰¾èƒ½å¤Ÿå°†æ•°æ®è¿›è¡Œå‡†ç¡®åˆ’åˆ†çš„æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•åœ¨æ•°æ®é‡ä¸æ˜¯å¾ˆå¤§æƒ…å†µä¸‹å¾ˆå¥æ•ˆã€‚æ”¯æŒå‘é‡æœºç§°ä¸º20ä¸–çºª90å¹´ä»£åˆ°21ä¸–çºªåˆçš„å® å„¿ã€‚
      + 2006å¹´ è¾›é¡¿å‘è¡¨é¢˜ä¸ºã€Šåˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®çš„ç»´åº¦çº¦å‡ã€‹çš„æ–‡ç« ï¼Œæå‡ºäº†æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆDNNï¼‰ï¼Œå¹¶æŒ‡å‡ºå¦‚æœæˆ‘ä»¬èƒ½å¤Ÿå°†ç¥ç»ç½‘ç»œçš„å±‚æ•°åŠ æ·±ï¼Œå¹¶ä¸”ç²¾å¿ƒè®¾è®¡è®­ç»ƒç½‘ç»œçš„æ–¹å¼ï¼Œé‚£ä¹ˆè¿™æ ·æ·±å±‚æ¬¡çš„ç¥ç»ç½‘ç»œå°±ä¼šå…·æœ‰è¶…å¼ºçš„è¡¨è¾¾èƒ½åŠ›å’Œå­¦ä¹ èƒ½åŠ›ã€‚

   2. æ·±åº¦å­¦ä¹ æ—¶ä»£

      + æ·±åº¦å­¦ä¹ é¦–å…ˆåœ¨è¯­éŸ³é¢†åŸŸå–å¾—çªç ´ã€‚å¾®è½¯çš„é‚“åŠ›é‚€è¯·è¾›é¡¿åŠ å…¥è¯­éŸ³è¯†åˆ«çš„æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„å¼€å‘ï¼Œä½¿è¯†åˆ«çš„å‡†ç¡®åº¦æœ‰äº†å¤§å¹…çš„æå‡ã€‚
      + æœºå™¨è§†è§‰ä¸“å®¶æé£é£ï¼Œå€ŸåŠ©ç½‘å‹çš„åŠ›é‡æ„é€ å‡ºäº†ImageNetè¿™æ ·ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜ç²¾åº¦ã€å¤šæ ‡ç­¾çš„å›¾åƒæ•°æ®åº“ã€‚äºæ˜¯æé£é£å¼€å§‹æ¯å¹´ä¸¾åŠä¸€æ¬¡å›¾åƒè¯†åˆ«å¤§èµ›ï¼šImageNetç«èµ›ã€‚2012å¹´ï¼Œè¾›é¡¿å’Œä»–çš„ä¸¤ä¸ªå­¦ç”Ÿé‡‡ç”¨æ·±å±‚æ¬¡çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰,åœ¨ImageNetç«èµ›ä¸­å°†åˆ†ç±»é”™è¯¯ç‡ä»25%é™åˆ°äº†17%ã€‚å°†æ·±åº¦ç½‘ç»œåšåˆ°8å±‚ï¼Œä¸”ä¸éœ€è¦ä»»ä½•é¢„å¤„ç†å°±èƒ½å°†å›¾åƒåˆ†ç±»ä»»åŠ¡åšåˆ°è¿™ä¹ˆå¥½ï¼Œè¿˜æ˜¯å¤´ä¸€æ¬¡ã€‚æ·±åº¦ç¥ç»ç½‘ç»œç§°ä¸ºäº†ImageNetç«èµ›çš„æ ‡é…ï¼Œä»AlexNetåˆ°GoogleNetï¼Œç½‘ç»œæ·±åº¦ä¸æ–­å¢åŠ ï¼Œå‡†ç¡®ç‡ä¸æ–­æå‡ã€‚2012å¹´åæ·±åº¦å­¦ä¹ å¼€å§‹åœ¨å­¦æœ¯åœˆæµè¡Œèµ·æ¥ã€‚

   3. æ·±åº¦å­¦ä¹ å‘å±•

      + 2011å¹´ è°·æ­ŒXå®éªŒå®¤çš„æ°å¤«å’Œå´æ©è¾¾ç­‰äººé‡‡ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œè®©è°·æ­Œå¤§è„‘æ·±åº¦ç¥ç»ç½‘ç»œè§‚çœ‹äº†ä»Youtubeä¸Šæå–å‡ºæ¥çš„30ä¸‡å¼ å›¾åƒï¼Œå¹¶è®©æœºå™¨è‡ªåŠ¨è¿›è¡Œç²¾ç®€ï¼Œè°·æ­Œå¤§è„‘è‡ªå·±å­¦å‡ºäº†ä¸€å¼ çŒ«è„¸ã€‚çœ‹åˆ°å‘å±•å‰æ™¯åï¼Œä»¥è°·æ­Œæœªä»£è¡¨çš„å„å¤§å…¬å¸å¼€å§‹ç–¯ç‹‚å¹¶è´­äººå·¥æ™ºèƒ½ã€äººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸å’Œå›¢é˜Ÿï¼Œä¿ƒä½¿æ›´å¤šçš„äººæ‰å’Œåˆ›ä¸šå…¬å¸æŠ•å…¥åˆ°äººå·¥æ™ºèƒ½å¤§æ½®ä¸­ã€‚

      + è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œ2013å¹´ï¼Œè°·æ­Œçš„æ‰˜é©¬æ–¯æå‡ºäº†Word2VecæŠ€æœ¯ï¼Œå®ƒå¯ä»¥éå¸¸å¿«æ·æœ‰æ•ˆåœ°è®¡ç®—å•è¯é—´çš„å‘é‡è¡¨ç¤ºï¼Œä¸ºå¤§è§„æ¨¡ä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œæŠ€æœ¯å¤„ç†äººç±»è¯­è¨€å¥ å®šäº†é‡è¦åŸºç¡€

      + 2014å¹´ï¼Œè°·æ­Œå¼€å§‹å°è¯•åˆ©ç”¨æ·±åº¦çš„ç¥ç»å¾ªç¯ç½‘ç»œæ¥å¤„ç†å„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼ŒåŒ…æ‹¬æœºå™¨ç¿»è¯‘ï¼Œè‡ªåŠ¨å¯¹è¯ï¼Œæƒ…ç»ªè¯†åˆ«ã€é˜…è¯»ç†è§£ç­‰ã€‚2016å¹´ï¼Œè°·æ­Œæœºå™¨ç¿»è¯‘æŠ€æœ¯å–å¾—é‡å¤§çªç ´ï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œå’Œæ³¨æ„åŠ›æœºæ™ºçš„æœºå™¨ç¿»è¯‘åœ¨å¤šç§è¯­è¨€ä¸Šå·²ç»åŸºæœ¬æ¥è¿‘äººç±»æ°´å¹³ã€‚

      + å¼ºåŒ–å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ çš„ç»“åˆï¼Œæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºæ¸¸æˆã€åšå¼ˆç­‰é¢†åŸŸåŒæ ·å–å¾—äº†é‡å¤§è¿›å±•ã€‚

        2015å¹´è¢«è°·æ­Œæ”¶è´­çš„DeepMindå›¢é˜Ÿç ”å‘äº†ä¸€ç§â€œé€šç”¨äººå·¥æ™ºèƒ½ç®—æ³•â€ï¼Œä»–å¯ä»¥åƒäººç±»ä¸€æ ·ï¼Œé€šè¿‡è§‚å¯Ÿè®¡ç®—æœºæ¸¸æˆå±å¹•è¿›è¡Œè‡ªæˆ‘å­¦ä¹ ï¼Œåˆ©ç”¨åŒä¸€å¥—ç½‘ç»œæ¶æ„å’Œè¶…å‚æ•°ï¼Œä»é›¶å¼€å§‹å­¦ä¹ æ¯ä¸€æ¬¾æ¸¸æˆï¼Œå¹¶æœ€ç»ˆæ‰“é€šäº†300å¤šæ¬¾é›…è¾¾åˆ©æ¸¸æˆï¼Œåœ¨æŸäº›æ¸¸æˆä¸Šçš„è¡¨ç°ç”šè‡³è¶…è¶Šäº†äººç±»ã€‚

      + 2016å¹´ DeepMindå›¢é˜Ÿåˆåœ¨åšå¼ˆé¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ã€‚AlphaGoä»¥4:1æˆ˜èƒœäººç±»å›´æ£‹å† å†›ã€‚2017å¹´ DeepMindå›¢é˜Ÿåˆ›é€ çš„ AlphaGo å‡çº§ç‰ˆ AlphaGo Zero ï¼Œå®ƒå¯ä»¥å®Œå…¨ä»é›¶å¼€å§‹å­¦ä¹ ä¸‹å›´æ£‹ï¼Œè€Œæ— éœ€å€Ÿé‰´ä»»ä½•äººç±»çš„ä¸‹æ£‹ç»éªŒã€‚ä»…ç»è¿‡å¤§çº¦3å¤©è®­ç»ƒï¼ŒAlphaGo Zeroå°±è¾¾åˆ°äº†æˆ˜èƒœæä¸–çŸ³çš„æ£‹åŠ›æ°´å¹³ã€‚è€Œåˆ°äº†21å¤©åï¼Œä¸–ç•Œä¸Šå·²ç»æ²¡æœ‰ä»»ä½•äººç±»æˆ–ç¨‹åºå¯ä»¥åœ¨å›´æ£‹ä¸Šæˆ˜èƒœå®ƒäº†ã€‚AlphaGo çš„æˆåŠŸä¸ä»…æ ‡å¿—ç€ä»¥æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸ºæ”¯æ’‘çš„æ–°ä¸€ä»£äººå·¥æ™ºèƒ½æŠ€æœ¯å¤§è·å…¨èƒœï¼Œæ›´æš—ç¤ºç€äººå·¥æ™ºèƒ½å…¨æ–°æ—¶ä»£çš„æ¥ä¸´ã€‚  

   4. æ·±åº¦å­¦ä¹ çš„å½±å“å› ç´ 

      1. å¤§æ•°æ®

         å¦‚æœæ²¡æœ‰è¶³å¤Ÿå¤§é‡çš„æ•°æ®è¾“å…¥ç»™æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå°±æ— æ³•å‘æŒ¥æ·±åº¦çš„ä½œç”¨ã€‚ä¼´éšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œå¾…æ‹Ÿåˆçš„å‚æ•°è‡ªç„¶ä¼šä¹Ÿä¼šå¢åŠ ï¼Œå¦‚æœæ²¡æœ‰ä¸å…¶ç›¸åŒ¹é…çš„æµ·é‡æ•°æ®æ¥è®­ç»ƒç½‘ç»œï¼Œè¿™äº›å‚æ•°å°±å®Œå…¨å˜æˆäº†å¯¼è‡´ç½‘ç»œè¿‡æ‹Ÿåˆçš„åƒåœ¾ï¼Œæ— æ³•å‘æŒ¥ä½œç”¨

      2. æ·±åº¦ç½‘ç»œæ¶æ„ï¼ˆæ•´ä¸ªç½‘ç»œä½“ç³»çš„æ„å»ºæ–¹å¼å’Œæ‹“æ‰‘è¿æ¥ç»“æ„ï¼‰

         é¢å¯¹å…·ä½“é—®é¢˜æ—¶ï¼Œåº”è¯¥é‡‡ç”¨ä»€ä¹ˆæ ·çš„ç½‘ç»œæ¶æ„ï¼Œå¦‚ä½•é€‰å–å‚æ•°ï¼Œå¦‚ä½•è®­ç»ƒè¿™ä¸ªç½‘ç»œï¼Œä»ç„¶æ˜¯å½±å“å­¦ä¹ æ•ˆç‡å’Œè§£å†³é—®é¢˜çš„é‡è¦å› ç´ ã€‚

         ç›®å‰ä¸»è¦åˆ†ä¸ºï¼š 

         + å‰é¦ˆç¥ç»ç½‘ç»œ  

           æ¯ä¸€å±‚çš„èŠ‚ç‚¹åªè·Ÿå®ƒç›¸é‚»å±‚èŠ‚ç‚¹è€Œä¸”æ˜¯å…¨éƒ¨èŠ‚ç‚¹ç›¸è¿ï¼ˆå…¨è¿æ¥çš„ï¼‰ï¼Œåˆ†ä¸ºè¾“å…¥å±‚ï¼Œéšè—å±‚ï¼Œè¾“å‡ºå±‚

         + å·ç§¯ç¥ç»ç½‘ç»œ

           å·ç§¯å±‚å’Œæ± åŒ–å±‚

           å›¾ä¸­æ¯ä¸€ä¸ªç«‹æ–¹ä½“éƒ½æ˜¯ä¸€ç³»åˆ—è§„åˆ™æ’åˆ—çš„äººå·¥ç¥ç»å…ƒçš„é›†åˆã€‚

           æ¯ä¸ªç¥ç»å…ƒåˆ°ä¸Šä¸€å±‚æ¬¡çš„è¿æ¥ç§°ä¸ºå·ç§¯æ ¸ï¼Œå®ƒä»¬éƒ½æ˜¯ä¸€ç§å±€åŸŸçš„å°çª—å£ã€‚

           å›¾ä¸­çš„å°é”¥å½¢å¯ä»¥ç†è§£ä¸ºä»é«˜å±‚çš„æŸä¸€ä¸ªç¥ç»å…ƒåˆ°ä½å±‚å¤šä¸ªç¥ç»å…ƒä¹‹é—´çš„è¿æ¥ã€‚è¿™ä¸ªå°é”¥å½¢åœ¨ç«‹æ–¹ä½“ä¸Šé€åƒç´ çš„å¹³ç§»å°±æ„æˆäº†ä¸¤å±‚æ¬¡ä¹‹é—´çš„æ‰€æœ‰è¿æ¥ã€‚åˆ°äº†æœ€åä¸¤å±‚ï¼Œå°ç«‹æ–¹ä½“è¢«å‹ç¼©æˆäº†ä¸€ä¸ªä¸€ç»´çš„å‘é‡ï¼Œè¿™å°±ä¸æ™®é€šçš„å‰é¦ˆç¥ç»ç½‘ç»œæ²¡æœ‰åŒºåˆ«ã€‚

           CNNè¿™ç§ç‰¹æ®Šçš„æ¶æ„å¯ä»¥å¾ˆå¥½åœ°åº”ç”¨äºå›¾åƒå¤„ç†ï¼Œå®ƒå¯ä»¥ä½¿åŸå§‹çš„å›¾åƒå³ä½¿åœ¨ç»å†è¿‡å¹³ç§»ã€ç¼©æ”¾ç­‰å˜æ¢åä»ç„¶å…·æœ‰å¾ˆé«˜çš„è¯†åˆ«å‡†ç¡®æ€§ã€‚æ­£æ˜¯å› ä¸ºå…·æœ‰è¿™æ ·ç‰¹æ®Šçš„æ¶æ„ï¼ŒCNNæ‰æˆåŠŸåº”ç”¨äºè®¡ç®—æœºè§†è§‰ã€å›¾åƒè¯†åˆ«ã€å›¾åƒç”Ÿæˆï¼Œç”šè‡³AIä¸‹å›´æ£‹ã€AIæ‰“æ¸¸æˆç­‰å¹¿é˜”é¢†åŸŸ

         + å¾ªç¯ç¥ç»ç½‘ç»œ
      
           è¾“å…¥å±‚ï¼Œè¾“å‡ºå±‚æ˜¯å•å±‚ï¼Œä¸­é—´çš„éšè—å±‚çš„èŠ‚ç‚¹ç›¸äº’è¿æ¥ã€‚éšè—å±‚å½¼æ­¤ä¹‹é—´è¿˜æœ‰å¤§é‡çš„è¿æ¥ã€‚
      
           RNNè¿™ç§ç‰¹æ®Šçš„æ¶æ„ä½¿å¾—ç½‘ç»œå½“å‰çš„è¿è¡Œä¸ä»…è·Ÿå½“å‰çš„è¾“å…¥æ•°æ®æœ‰å…³ï¼Œè€Œä¸”è¿˜ä¸ä¹‹å‰çš„æ•°æ®æœ‰å…³ã€‚å› æ­¤ï¼Œè¿™ç§ç½‘ç»œç‰¹åˆ«é€‚åˆå¤„ç†è¯¸å¦‚è¯­è¨€ã€éŸ³ä¹ã€è‚¡ç¥¨æ›²çº¿ç­‰åºåˆ—ç±»å‹çš„æ•°æ®ï¼Œæ•´ä¸ªç½‘ç»œçš„å¾ªç¯ç»“æ„å¯ä»¥å¾ˆå¥½åœ°åº”ä»˜è¾“å…¥åºåˆ—ä¹‹ä¸­å­˜åœ¨çš„é•¿ç¨‹è®°å¿†æ€§å’Œå‘¨æœŸæ€§
      
         + è®­ç»ƒæ–¹å¼
      
           è®­ç»ƒæ–¹å¼ä¹Ÿä¼šå¯¹ç»“æœäº§ç”Ÿå¾ˆå¤§å½±å“ã€‚å¦‚æœå…ˆå°†å°‘é‡ç‰¹å®šæ ‡ç­¾çš„æ•°æ®è¾“å…¥ç½‘ç»œï¼Œç„¶åå†æ‹¿å‰©ä¸‹çš„æ•°æ®å»è®­ç»ƒå®ƒï¼Œå°±ä¼šæ¯”ä¸€è‚¡è„‘æŠŠæ‰€æœ‰ä¾¿ç­¾æ•°æ®éƒ½è¾“å…¥æ›´åŠ æœ‰æ•ˆï¼Œä»è€Œæé«˜ç½‘ç»œçš„â€œå­¦ä¹ â€èƒ½åŠ›ã€‚
      
      3. GPU 
      
         GPUéå¸¸æ“…é•¿å¤§è§„æ¨¡çš„å¼ é‡ï¼ˆé«˜é˜¶çŸ©é˜µï¼‰è¿ç®—ï¼Œå¹¶ä¸”å¯ä»¥ä¸ºè¿™ç§è¿ç®—åŠ é€Ÿï¼Œå¯¹åŒ…å«å¤šä¸ªæ•°å€¼çš„å¼ é‡è¿ç®—æ‰€éœ€çš„å¹³å‡æ—¶é—´è¿œä½äºå¯¹æ¯ä¸ªæ•°å­—çš„è¿ç®—æ—¶é—´
      
   5. æ·±åº¦å­¦ä¹ çš„æˆåŠŸ

      æ·±åº¦å­¦ä¹ é‡è¦çš„æœ¬é¢†åœ¨äºå®ƒå¯ä»¥ä»æµ·é‡çš„æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ ï¼ŒæŠ½å–æ•°æ®ä¸­çš„ç‰¹å¾ã€‚

      + ç‰¹å¾å­¦ä¹ 

        æ·±åº¦ç¥ç»ç½‘ç»œä¼šæŠŠä¸åŒçš„ä¿¡æ¯è¡¨è¾¾åˆ°ä¸åŒå±‚æ¬¡çš„ç½‘ç»œå•å…ƒä¸­ï¼Œè¿™ä¸€æç‚¼è¿‡ç¨‹å®Œå…¨ä¸éœ€è¦æ‰‹å·¥å¹²é¢„ï¼Œå…¨å‡­æœºå™¨å­¦ä¹ è¿‡ç¨‹è‡ªåŠ¨å®Œæˆã€‚æ·±åº¦å­¦ä¹ çš„æœ¬è´¨å°±æ˜¯è¿™ç§è‡ªåŠ¨æå–ç‰¹å¾çš„åŠŸèƒ½ã€‚

      + è¿ç§»å­¦ä¹ 

        æŠŠä¸€ä¸ªè®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œåˆ‡å¼€ï¼Œç„¶åå†æŠŠå®ƒæ‹¼æ¥åˆ°å¦ä¸€ä¸ªç¥ç»ç½‘ç»œä¸Šï¼Œå‰åŠéƒ¨åˆ†ç”¨äºç‰¹å¾æå–ï¼ŒååŠéƒ¨åˆ†ç½‘ç»œå»è§£å†³å¦ä¸€ä¸ªå®Œå…¨ä¸åŒçš„é—®é¢˜ã€‚

2. PyTorchç®€ä»‹

   1. PyTorchå®‰è£…

   2. ä¸Pythonå®Œç¾èåˆ

      ä½¿ç”¨Pytorchä¸ä½¿ç”¨å…¶ä»–Pythonç¨‹åºåŒ…æ²¡æœ‰ä»»ä½•åŒºåˆ«
      
      ä¸æ­¤å½¢æˆé²œæ˜å¯¹æ¯”çš„æ˜¯TensorFlowï¼ŒTensorFlowä¼šå°†ä¸€ä¸ªæ·±åº¦å­¦ä¹ ä»»åŠ¡åˆ†ä¸ºå®šä¹‰ä¸ºè®¡ç®—å›¾å’Œæ‰§è¡Œè®¡ç®—è¿‡ç¨‹ï¼Œè€Œå®šä¹‰è®¡ç®—å›¾çš„è¿‡ç¨‹å°±å¥½åƒåœ¨ä½¿ç”¨ä¸€å¥—å…¨æ–°çš„è¯­è¨€ã€‚PyTorchå°±æ²¡æœ‰è¿™ä¸ªç¼ºç‚¹ï¼Œä»å®šä¹‰è®¡ç®—å›¾åˆ°æ‰§è¡Œè®¡ç®—æ˜¯ä¸€æ°”å‘µæˆçš„ã€‚
      
   3. å¼ é‡ï¼ˆtensorï¼‰è®¡ç®—

      PyTorchçš„è¿ç®—å•å…ƒå«åšå¼ é‡ï¼Œ1é˜¶å¼ é‡å³ä¸º1ç»´æ•°ç»„ï¼ˆå‘é‡vectorï¼‰ï¼Œ2é˜¶å¼ é‡ä¸º2ç»´æ•°ç»„ï¼ˆçŸ©é˜µmatrixï¼‰ï¼Œ3é˜¶å¼ é‡å³ä¸º3ç»´æ•°ç»„

      ```python
      import torch
      x=torch.rand(5,3)
      x
      tensor([[0.1440, 0.7954, 0.8075],
              [0.1011, 0.0410, 0.4783],
              [0.1711, 0.4874, 0.0733],
              [0.8815, 0.3930, 0.4344],
              [0.8639, 0.1563, 0.8560]])
      
      ```
      
      ```python
      y=torch.ones(5,3)
      y
      tensor([[1., 1., 1.],
              [1., 1., 1.],
              [1., 1., 1.],
              [1., 1., 1.],
              [1., 1., 1.]])
      ```
      
      ```python
      # pytorhçŸ©é˜µå‰ä¹˜æ³• mm() ,è½¬ç½®t()
      q=x.mm(y.t())
      q
      tensor([[1.7469, 1.7469, 1.7469, 1.7469, 1.7469],
              [0.6204, 0.6204, 0.6204, 0.6204, 0.6204],
              [0.7319, 0.7319, 0.7319, 0.7319, 0.7319],
              [1.7089, 1.7089, 1.7089, 1.7089, 1.7089],
              [1.8762, 1.8762, 1.8762, 1.8762, 1.8762]])
      ```
      
      ```python
      # pytorhå¼ é‡ä¸Numpyæ•°ç»„ä¹‹é—´çš„è½¬æ¢
      import numpy as np
      x_tensor=torch.randn(2,3)
      y_numpy=np.random.randn(2,3)
      # å°†å¼ é‡è½¬æ¢ä¸ºnumpy
      x_numpy=x_tensor.numpy()
      # å°†numpyè½¬åŒ–ä¸ºå¼ é‡
      y_tensor=torch.from_numpy(y_numpy)
      print(x_tensor)
      print(x_numpy)
      print(y_numpy)
      print(y_tensor)
      
      tensor([[ 1.6723,  0.8274,  1.4538],
              [ 0.5076, -1.6918,  0.1204]])
      [[ 1.672333    0.8274111   1.453827  ]
       [ 0.5075982  -1.691759    0.12042859]]
      [[-1.53580661  1.05183357 -0.13190343]
       [ 0.26008687 -0.76392427  0.49671979]]
      tensor([[-1.5358,  1.0518, -0.1319],
              [ 0.2601, -0.7639,  0.4967]], dtype=torch.float64)
      ```
      
      ```python
      # GPUä¸Šçš„å¼ é‡è®¡ç®—
      if torch.cuda.is_available():
          x=x.cuda()
          y=y.cuda()
          print(x+y)
          
      tensor([[1.1440, 1.7954, 1.8075],
              [1.1011, 1.0410, 1.4783],
              [1.1711, 1.4874, 1.0733],
              [1.8815, 1.3930, 1.4344],
              [1.8639, 1.1563, 1.8560]], device='cuda:0')
      ```
      
   4. åŠ¨æ€è®¡ç®—å›¾

      è®¡ç®—å›¾ç”¨äºè§£å†³ç”¨äºè§£å†³åå‘ä¼ æ’­ç®—æ³•é—®é¢˜ã€‚å½“å‰é¦ˆè¿ç®—æ­¥éª¤å®Œæˆä¹‹åï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶å°±ä¼šè‡ªåŠ¨æ­å»ºä¸€ä¸ªè®¡ç®—å›¾ï¼Œé€šè¿‡è¿™ä¸ªå›¾ï¼Œå°±å¯ä»¥è®©åå‘ä¼ æ’­ç®—æ³•è¿›è¡Œã€‚

      è‡ªåŠ¨å¾®åˆ†å˜é‡æ˜¯é€šè¿‡3ä¸ªé‡è¦çš„å±æ€§dataï¼ˆå¼ é‡ï¼‰ã€gradï¼ˆæ¢¯åº¦å€¼ï¼‰ä»¥åŠgrad_fnï¼ˆè·å¾—è®¡ç®—å›¾çš„ä¸Šä¸€ä¸ªèŠ‚ç‚¹ï¼‰æ¥å®ç°çš„ã€‚åœ¨é‡‡ç”¨äº†è‡ªåŠ¨å¾®åˆ†å˜é‡ä»¥åï¼Œæ— è®ºä¸€ä¸ªè®¡ç®—è¿‡ç¨‹å¤šä¹ˆå¤æ‚ï¼Œç³»ç»Ÿéƒ½ä¼šè‡ªåŠ¨æ„é€ ä¸€å¼ è®¡ç®—å›¾æ¥è®°å½•æ‰€æœ‰çš„è¿ç®—è¿‡ç¨‹ã€‚

      ```python
      # å¯¼å…¥è‡ªåŠ¨å¾®åˆ†å˜é‡çš„åŒ…
      # from torch.autograd import Variable
      # requires_grad=Trueæ˜¯ä¸ºäº†ä¿è¯åœ¨åå‘ä¼ æ’­ç®—æ³•ä¸­è·å¾—æ¢¯åº¦ä¿¡æ¯
      # x=Variable(torch.ones(2,2),requires_grad=True) Variableè¢«åºŸå¼ƒ
      x=torch.ones(2,2,requires_grad=True)
      x
      tensor([[1., 1.],
              [1., 1.]], requires_grad=True)
      ```

      ```python
      y=x+2
      y
      tensor([[3., 3.],
              [3., 3.]], grad_fn=<AddBackward0>)
      ```

      ```python
      y.data
      tensor([[3., 3.],
              [3., 3.]])
      ```

      ```python
      #è¿”å›ä¸Šä¸€ä¸ªè®¡ç®—å›¾èŠ‚ç‚¹
      y.grad_fn
      <AddBackward0 at 0x1df0dc7f640>
      ```

      ```python
      # *æ˜¯ç‚¹ä¹˜ï¼Œåªæœ‰ç›¸åŒä½ç½®çš„å…ƒç´ ç›¸ä¹˜
      z=y*y
      z
      tensor([[9., 9.],
              [9., 9.]], grad_fn=<MulBackward0>)
      ```

      ```python
      z.grad_fn
      <MulBackward0 at 0x1df0dc9b280>
      ```

      ```python
      # torch.meanå¯¹çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ æ±‚å’Œå†é™¤ä»¥å…ƒç´ çš„ä¸ªæ•°ã€‚
      t=torch.mean(z)
      t
      tensor(9., grad_fn=<MeanBackward0>)
      ```

      ```python
      # backward()åå‘æ¢¯åº¦ä¼ æ’­ï¼Œè‡ªåŠ¨è¿›è¡Œæ±‚å¯¼è®¡ç®—
      # åªæœ‰å¶ç»“ç‚¹æ‰å¯ä»¥é€šè¿‡.backward()è·å¾—æ¢¯åº¦ä¿¡æ¯ï¼Œzå’Œyä¸æ˜¯å¶ç»“ç‚¹ï¼Œæ‰€ä»¥æ²¡æœ‰æ¢¯åº¦ä¿¡æ¯
      # retain_graph=True ä½¿å¾—t.backwardèƒ½è¿è¡Œå¾ˆå¤šæ¬¡ï¼Œæ²¡æœ‰backwardæ™ºèƒ½è¿è¡Œä¸€æ¬¡
      t.backward(retain_graph=True)
      print(z.grad)
      print(y.grad)
      print(x.grad)
      None
      None
      tensor([[3., 3.],
              [3., 3.]])
      ```

   5. PyTorchå®ä¾‹ï¼šé¢„æµ‹æˆ¿ä»·

      1. å‡†å¤‡æ•°æ®

         ```python
         # æ„é€ 0~50ä¹‹é—´å‡åŒ€æ•°å­—ä½œä¸ºæ—¶é—´å˜é‡ã€‚
         x=torch.linspace(0,50,steps=50,requires_grad=True).type(torch.float)
         x
         tensor([ 0.0000,  1.0204,  2.0408,  3.0612,  4.0816,  5.1020,  6.1224,  7.1429,
                  8.1633,  9.1837, 10.2041, 11.2245, 12.2449, 13.2653, 14.2857, 15.3061,
                 16.3265, 17.3469, 18.3673, 19.3878, 20.4082, 21.4286, 22.4490, 23.4694,
                 24.4898, 25.5102, 26.5306, 27.5510, 28.5714, 29.5918, 30.6122, 31.6327,
                 32.6531, 33.6735, 34.6939, 35.7143, 36.7347, 37.7551, 38.7755, 39.7959,
                 40.8163, 41.8367, 42.8571, 43.8776, 44.8980, 45.9184, 46.9388, 47.9592,
                 48.9796, 50.0000])
         ```

         ```python
         # ç”Ÿæˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º5çš„æ­£æ€åˆ†å¸ƒã€‚
         rand=torch.randn(50).type(torch.float)*5
         # torch.normal(mean=0, std=10,out=50)
         rand
         tensor([-9.5013, -0.2001, -0.2612,  7.3100,  7.8910, -6.8819, -2.4307, -2.4865,
                  5.9178,  4.6767,  2.6463, -4.2847, -1.1919, -7.6735,  6.0805, -4.8176,
                  4.2334, -6.2658,  6.2607,  0.8406, -8.8556,  6.1883, 12.6984,  0.4164,
                  2.1272,  5.9475, -5.7067,  5.4889,  1.4164,  5.9655,  0.4942,  2.8694,
                 -2.0671,  0.4787, -3.0500,  5.3546, -0.5102,  3.3566, -0.3483,  3.2969,
                  2.4644,  0.0407,  5.4788, -7.3005,  0.5329,  3.5430, -3.5318, -4.6006,
                 -8.2579,  1.2810])
         ```

         ```python
         # ç”Ÿæˆæˆ¿ä»·
         y=x+rand
         y
         tensor([-2.5061, -8.4511,  8.3336,  0.6089,  8.8587,  0.4199,  6.9523,  2.9417,
                 11.2004,  5.9490, 15.7981, 16.6783,  5.6091, 13.6873, 15.6817, 13.3907,
                 28.9034, 15.6045, 19.9990, 24.7943, 22.4937, 24.9002, 19.5600, 18.0025,
                 26.3569, 26.2317, 28.3032, 27.7680, 24.7899, 32.1754, 35.6954, 25.2297,
                 27.5482, 36.3927, 26.6795, 37.5358, 27.3953, 38.8195, 35.6925, 36.0569,
                 36.8523, 53.8654, 39.3955, 43.5647, 45.5984, 47.2127, 46.3957, 46.6790,
                 49.8011, 54.2800])
         ```

         ç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†

         ```python
         x_train=x[:-5]
         x_test=x[-5:]
         y_train=y[:-5]
         y_test=y[-5:]
         ```

         å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå¯è§†åŒ–

         ```python
         # å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå¯è§†åŒ–
         import matplotlib.pyplot as plt
         # è®¾å®šç»˜åˆ¶çª—å£å¤§å°ä¸º8*6inch
         plt.figure(figsize=(8,6))
         # ç»˜åˆ¶æ•°æ®ï¼Œç”±äºxå’Œyéƒ½æ˜¯Variableï¼Œéœ€è¦ç”¨dataè·å–å®ƒä»¬åŒ…è£¹çš„Tensor,å¹¶è½¬æˆNumpy
         plt.plot(x_train.data.numpy(),y_train.data.numpy(),'o')
         # è®¾ç½®Xè½´æ ‡ç­¾
         plt.xlabel('X')
         plt.ylabel('Y')
         plt.show()
         ```

         ![](.\2-1.jpg)

      2. æ¨¡å‹è®¾è®¡

         æˆ‘ä»¬å¸Œæœ›å¾—åˆ°ä¸€æ¡å°½å¯èƒ½ä»ä¸­é—´ç©¿è¶Šè¿™äº›æ•°æ®æ•£ç‚¹çš„æ‹Ÿåˆç›´çº¿ã€‚è®¾è¿™æ¡ç›´çº¿æ–¹ç¨‹ä¸º
         $$
         y=ax+b
         $$
         æ¥ä¸‹æ¥çš„é—®é¢˜æ˜¯ï¼Œæ±‚è§£å‡ºå‚æ•°a,bçš„æ•°å€¼ã€‚æˆ‘ä»¬å¯ä»¥å°†æ¯ä¸€ä¸ªæ•°æ®ç‚¹ä»£å…¥è¿™ä¸ªæ–¹ç¨‹ä¸­ï¼Œè®¡ç®—å‡º
         $$
   \hat{y_i}=ax_i+b
         $$
         
         æ˜¾ç„¶
         $$
         \hat{y_i}
         $$
         è¶Šé è¿‘
         $$
         y_i
         $$
         è¶Šå¥½ï¼Œå®šä¹‰å¹³å‡æŸå¤±å‡½æ•°
         $$
         L=\frac{1}{N}\sum_{i=1}^N(y_i-\hat{y_i})^2=\frac{1}{N}\sum_{i=1}^N(y_i-ax_i-b)^2
         $$
         
         å¹¶è®©å®ƒå°½å¯èƒ½çš„å°ã€‚ç”±äº
         $$
         x_iå’Œy_i
         $$
         éƒ½æ˜¯å›ºå®šçš„æ•°ï¼Œè€Œåªæœ‰aå’Œbæ˜¯å˜é‡ï¼Œé‚£ä¹ˆLæœ¬è´¨ä¸Šå°±æ˜¯aå’Œbçš„å‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¦å¯»æ‰¾æœ€ä¼˜çš„aã€bç»„åˆï¼Œè®©Læœ€å°åŒ–ã€‚
         
         æˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥åå¤è¿­ä»£aå’Œbï¼Œä»è€Œè®©Lè¶Šå˜è¶Šå°ã€‚
         $$
         a_{t+1}=a_t-\alpha \left. \frac{\partial L}{\partial a}  \right| _{a=a_t}
         $$
         
         $$
         b_{t+1}=b_t-\alpha \left. \frac{\partial L}{\partial b}  \right| _{b=b_t}
         $$
         
         $$
         \alphaä¸ºå­¦ä¹ ç‡ï¼Œå®ƒå¯ä»¥è°ƒèŠ‚æ¢¯åº¦ä¸‹é™å¿«æ…¢ï¼Œ\alphaè¶Šå¤§ï¼Œaã€bæ›´æ–°å¾—è¶Šå¿«ï¼Œä½†æ˜¯è®¡ç®—å¾—åˆ°çš„æœ€ä¼˜å€¼Lå°±æœ‰å¯èƒ½è¶Šä¸å‡†
         $$
         
         åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å‡ºLå¯¹aã€bçš„åå¯¼æ•°ï¼Œåˆ©ç”¨PyTorchçš„backwardï¼ˆï¼‰å¯ä»¥éå¸¸æ–¹ä¾¿åœ°å°†è¿™ä¸¤ä¸ªåå¯¼æ•°è®¡ç®—å‡ºæ¥ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸€æ­¥æ­¥åœ°æ›´æ–°aå’Œbçš„æ•°å€¼å°±å¯ä»¥äº†ã€‚å½“è¾¾åˆ°ä¸€å®šçš„è¿­ä»£æ­¥æ•°ä¹‹åï¼Œæœ€ç»ˆaå’Œbçš„æ•°å€¼å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„æœ€ä¼˜æ•°å€¼ã€‚
         
      3. è®­ç»ƒ
      
         ```python
         # å®šä¹‰ä¸¤ä¸ªè‡ªåŠ¨å¾®åˆ†å˜é‡aå’Œb(a,béšæœº)
         # a=Variable(torch.rand(1),requires_grad=True)  Variableå·²ç»è¢«åºŸå¼ƒ
         # b=Variable(torch.rand(1),requires_grad=True)
         a=torch.rand(1,requires_grad=True)
         b=torch.rand(1,requires_grad=True)
         # è®¾ç½®å­¦ä¹ ç‡
         learning_rate=0.0001
         ```
      
         ```python
         # aå’Œbçš„è¿­ä»£è®¡ç®—
         for i in range(500):
             predictions=a*x_train+b
             loss=torch.mean((predictions-y_train)**2)
             print('loss:',loss)
             loss.backward()
         #add_    
             a.data.add_(-learning_rate*a.grad)
             b.data.add_(-learning_rate*b.grad)
         # åœ¨æ›´æ–°å®Œaã€bçš„æ•°å€¼åï¼Œéœ€è¦æ¸…ç©ºaä¸­çš„çš„æ¢¯åº¦ä¿¡æ¯ï¼Œ
         # å¦åˆ™å®ƒä¼šåœ¨ä¸‹ä¸€æ­¥è¿­ä»£çš„æ—¶å€™ç´¯åŠ 
             a.grad.zero_()
             b.grad.zero_()
         #å¤ªé•¿ï¼Œåªå†™äº†è¾“å‡ºäº†æœ€åä¸€ä¸ªloss
         loss: tensor(23.5075, grad_fn=<MeanBackward0>)
         print(a.data,b.data)
         tensor([0.9775]) tensor([0.3045])
         ```
      
         å°†åŸå§‹çš„æ•°æ®æ•£ç‚¹è”åˆæ‹Ÿåˆçš„ç›´çº¿é€šè¿‡å›¾å½¢ç”»å‡ºæ¥
      
         ```python
         x_data=x_train.data.numpy()
         y_data=y_train.data.numpy()
         plt.figure(figsize=(10,7))
         #ç»˜åˆ¶è®­ç»ƒé›†æ•£ç‚¹
         plt1, =plt.plot(x_data,y_data,'o')
         # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
         plt2, =plt.plot(x_data,a.data.numpy()*x_data+b.data.numpy())
         # åæ ‡æ ‡æ³¨
         plt.xlabel("X")
         plt.ylabel("Y")
         str1=str(a.data.numpy()[0])+'x+'+str(b.data.numpy()[0])
         plt.legend([plt1,plt2],['train_data',str1])
         plt.show()
         ```
         
      
      ![](.\2-2.jpg)
      
      4. é¢„æµ‹
      
         ç”¨æµ‹è¯•æ•°æ®é›†è¿›è¡Œæµ‹è¯•
      
         ```python
         predictions=a*x_test+b
         predictions
         tensor([45.6905, 46.6988, 47.7070, 48.7153, 49.7235], grad_fn=<AddBackward0>)
      
         x_data=x_train.data.numpy()
         y_data=y_train.data.numpy()
         x_pred=x_test.data.numpy()
         y_pred=y_test.data.numpy()
         plt.figure(figsize=(10,7))
         #ç»˜åˆ¶è®­ç»ƒé›†æ•£ç‚¹
         plt1, =plt.plot(x_data,y_data,'o')
         plt2, =plt.plot(x_pred,y_pred,'s')
         # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
         plt3, =plt.plot(x_data,a.data.numpy()*x_data+b.data.numpy())
         # ç»˜åˆ¶é¢„æµ‹æ•°æ®
         plt4, =plt.plot(x_pred,a.data.numpy()*x_pred+b.data.numpy())
         plt.xlabel('X')
         plt.ylabel('Y')
         str1=str(a.data.numpy()[0])+'x+'+str(b.data.numpy()[0])
         plt.legend([plt1,plt2,plt3],['train_data','test_data',str1])
         plt.savefig("2-3.jpg")
         plt.show()
         ```
         
         ![](.\2-3.jpg)
         
         

3. å•è½¦é¢„æµ‹å™¨ï¼šä½ çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ

   è¿ç”¨PyTorchåŠ¨æ‰‹æ­å»ºä¸€ä¸ªå…±äº«å•è½¦é¢„æµ‹å™¨ï¼Œåœ¨å®æˆ˜ä¸­æŒæ¡ç¥ç»å…ƒã€ç¥ç»å…ƒã€æ¿€æ´»å‡½æ•°ã€æœºå™¨å­¦ä¹ ç­‰åŸºæœ¬æ¦‚å¿µï¼Œä»¥åŠæ•°æ®é¢„å¤„ç†çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæ­ç§˜ç¥ç»ç½‘ç»œè¿™ä¸ªâ€œé»‘ç®±â€ï¼Œçœ‹çœ‹å®ƒå¦‚ä½•å·¥ä½œï¼Œå“ªä¸ªç¥ç»å…ƒèµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚

   ```python
   #å¯¼å…¥éœ€è¦ä½¿ç”¨çš„åº“
   import numpy as np
   import pandas as pd #è¯»å–csvæ–‡ä»¶çš„åº“
   import matplotlib.pyplot as plt
   import torch
   #from torch.autograd import Variable
   import torch.optim as optim
   
   # è®©è¾“å‡ºçš„å›¾å½¢ç›´æ¥åœ¨Notebookä¸­æ˜¾ç¤º
   %matplotlib inline
   data_path="hour.csv"
   rides = pd.read_csv(data_path)
   # head()è¯»å–5è¡Œæ•°æ®å¹¶æ˜¾ç¤ºï¼ŒæŸ¥çœ‹æ•°æ®æ ¼å¼
   rides.head()
   ```

   ![](.\3-1.jpg)

   ```python
   #æˆ‘ä»¬å–å‡ºæœ€åä¸€åˆ—çš„å‰50æ¡è®°å½•æ¥è¿›è¡Œé¢„æµ‹
   counts = rides['cnt'][:50]
   
   #è·å¾—å˜é‡xï¼Œå®ƒæ˜¯1ï¼Œ2ï¼Œâ€¦â€¦ï¼Œ50
   x = np.arange(len(counts))
   
   # å°†countsè½¬æˆé¢„æµ‹å˜é‡ï¼ˆæ ‡ç­¾ï¼‰ï¼šy
   y = np.array(counts)
   
   # ç»˜åˆ¶ä¸€ä¸ªå›¾å½¢ï¼Œå±•ç¤ºæ›²çº¿é•¿çš„æ ·å­
   plt.figure(figsize = (8, 6)) #è®¾å®šç»˜å›¾çª—å£å¤§å°
   plt.plot(x, y, 'o-') # ç»˜åˆ¶åŸå§‹æ•°æ®
   plt.xlabel('X') #æ›´æ”¹åæ ‡è½´æ ‡æ³¨
   plt.ylabel('Y') #æ›´æ”¹åæ ‡è½´æ ‡æ³¨
   plt.savefig("3-2.jpg")
   plt.show()
   ```

   ![](.\3-2.jpg)

   1. ç”¨çº¿æ€§å›å½’å¯¹æ›²çº¿è¿›è¡Œæ‹Ÿåˆï¼Œå°½ç®¡æ•ˆæœå¾ˆå·®ï¼ˆå›é¡¾ä¸Šä¸€ç« èŠ‚å†…å®¹ï¼‰

      ```python
      #æˆ‘ä»¬å–å‡ºæ•°æ®åº“çš„æœ€åä¸€åˆ—çš„å‰50æ¡è®°å½•æ¥è¿›è¡Œé¢„æµ‹
      counts = rides['cnt'][:50]
      
      # åˆ›å»ºå˜é‡xï¼Œå®ƒæ˜¯1ï¼Œ2ï¼Œâ€¦â€¦ï¼Œ50
      x = torch.tensor(np.arange(len(counts)), dtype=torch.double, requires_grad = True)
      
      # å°†countsè½¬æˆé¢„æµ‹å˜é‡ï¼ˆæ ‡ç­¾ï¼‰ï¼šy
      y = torch.tensor(np.array(counts), dtype=torch.double, requires_grad = True)
      
      a = torch.rand(1, dtype=torch.double, requires_grad = True) #åˆ›å»ºaå˜é‡ï¼Œå¹¶éšæœºèµ‹å€¼åˆå§‹åŒ–
      b = torch.rand(1, dtype=torch.double, requires_grad = True) #åˆ›å»ºbå˜é‡ï¼Œå¹¶éšæœºèµ‹å€¼åˆå§‹åŒ–
      print('Initial parameters:', [a, b])
      learning_rate = 0.00001 #è®¾ç½®å­¦ä¹ ç‡
      for i in range(10000):
          ### å¢åŠ äº†è¿™éƒ¨åˆ†ä»£ç ï¼Œæ¸…ç©ºå­˜å‚¨åœ¨å˜é‡aï¼Œbä¸­çš„æ¢¯åº¦ä¿¡æ¯ï¼Œä»¥å…åœ¨backwardçš„è¿‡ç¨‹ä¸­ä¼šåå¤ä¸åœåœ°ç´¯åŠ 
          predictions = a * x+ b  #è®¡ç®—åœ¨å½“å‰aã€bæ¡ä»¶ä¸‹çš„æ¨¡å‹é¢„æµ‹æ•°å€¼
          loss = torch.mean((predictions - y) ** 2) #é€šè¿‡ä¸æ ‡ç­¾æ•°æ®yæ¯”è¾ƒï¼Œè®¡ç®—è¯¯å·®
          print('loss:', loss)
          loss.backward() #å¯¹æŸå¤±å‡½æ•°è¿›è¡Œæ¢¯åº¦åä¼ 
          a.data.add_(- learning_rate * a.grad)  #åˆ©ç”¨ä¸Šä¸€æ­¥è®¡ç®—ä¸­å¾—åˆ°çš„açš„æ¢¯åº¦ä¿¡æ¯æ›´æ–°aä¸­çš„dataæ•°å€¼
          b.data.add_(- learning_rate * b.grad)  #åˆ©ç”¨ä¸Šä¸€æ­¥è®¡ç®—ä¸­å¾—åˆ°çš„bçš„æ¢¯åº¦ä¿¡æ¯æ›´æ–°bä¸­çš„dataæ•°å€¼
          a.grad.zero_() #æ¸…ç©ºaçš„æ¢¯åº¦æ•°å€¼
          b.grad.zero_() #æ¸…ç©ºbçš„æ¢¯åº¦æ•°å€¼
      ```

      ç”¨çº¿æ€§å›å½’è¿›è¡Œæ‹Ÿåˆ

      ```python
      x_data=x.data.numpy()
      y_data=y.data.numpy()
      plt.figure(figsize=(10,7))
      #ç»˜åˆ¶è®­ç»ƒé›†æ•£ç‚¹
      plt1, =plt.plot(x_data,y_data,'o')
      # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿
      plt2, =plt.plot(x_data,a.data.numpy()*x_data+b.data.numpy())
      # åæ ‡æ ‡æ³¨
      plt.xlabel("X")
      plt.ylabel("Y")
      str1=str(a.data.numpy()[0])+'x+'+str(b.data.numpy()[0])
      plt.legend([plt1,plt2],['data',str1])
      plt.savefig("3-3.jpg")
      plt.show()
      ```

      ![](.\3-3.jpg)

   2. ç¬¬ä¸€ä¸ªäººå·¥ç¥ç»ç½‘ç»œé¢„æµ‹å™¨ï¼ˆå•è½¦é¢„æµ‹å™¨1.0ï¼‰

      è¾“å…¥å±‚1ä¸ªå•å…ƒï¼Œéšå«å±‚1å±‚æœ‰10ä¸ªå•å…ƒï¼Œè¾“å‡ºå±‚1ä¸ªå•å…ƒçš„äººå·¥ç¥ç»ç½‘ç»œ
      
      ```python
      #å–å‡ºæ•°æ®åº“ä¸­çš„æœ€åä¸€åˆ—çš„å‰50æ¡è®°å½•æ¥è¿›è¡Œé¢„æµ‹
      counts = rides['cnt'][:50]
      
      #åˆ›å»ºå˜é‡xï¼Œå®ƒæ˜¯1ï¼Œ2ï¼Œâ€¦â€¦ï¼Œ50
      x = torch.tensor(np.arange(len(counts), dtype = float), requires_grad = True)
      
      # å°†countsè½¬æˆé¢„æµ‹å˜é‡ï¼ˆæ ‡ç­¾ï¼‰ï¼šy
      y = torch.tensor(np.array(counts, dtype = float), requires_grad = True)
      
      # è®¾ç½®éšå«å±‚ç¥ç»å…ƒçš„æ•°é‡
      sz = 10
      
      # åˆå§‹åŒ–æ‰€æœ‰ç¥ç»ç½‘ç»œçš„æƒé‡ï¼ˆweightsï¼‰å’Œé˜ˆå€¼ï¼ˆbiasesï¼‰
      weights = torch.randn((1, sz), dtype = torch.double, requires_grad = True) #1*10çš„è¾“å…¥åˆ°éšå«å±‚çš„æƒé‡çŸ©é˜µ
      biases = torch.randn(sz, dtype = torch.double, requires_grad = True) #å°ºåº¦ä¸º10çš„éšå«å±‚èŠ‚ç‚¹åç½®å‘é‡
      weights2 = torch.randn((sz, 1), dtype = torch.double, requires_grad = True) #10*1çš„éšå«åˆ°è¾“å‡ºå±‚æƒé‡çŸ©é˜µ
      
      learning_rate = 0.001 #è®¾ç½®å­¦ä¹ ç‡
      losses = []
      
      # å°† x è½¬æ¢ä¸º(50,1)çš„ç»´åº¦ï¼Œä»¥ä¾¿ä¸ç»´åº¦ä¸º(1,10)çš„weightsçŸ©é˜µç›¸ä¹˜
      x = x.view(50, -1)
      # å°† y è½¬æ¢ä¸º(50,1)çš„ç»´åº¦
      y = y.view(50, -1)
      
      for i in range(100000):
          # ä»è¾“å…¥å±‚åˆ°éšå«å±‚çš„è®¡ç®—
          hidden = x * weights + biases
          # å°†sigmoidå‡½æ•°ä½œç”¨åœ¨éšå«å±‚çš„æ¯ä¸€ä¸ªç¥ç»å…ƒä¸Š
          hidden = torch.sigmoid(hidden)
          #print(hidden.size())
          # éšå«å±‚è¾“å‡ºåˆ°è¾“å‡ºå±‚ï¼Œè®¡ç®—å¾—åˆ°æœ€ç»ˆé¢„æµ‹
          predictions = hidden.mm(weights2)
          #print(predictions.size())
          # é€šè¿‡ä¸æ ‡ç­¾æ•°æ®yæ¯”è¾ƒï¼Œè®¡ç®—å‡æ–¹è¯¯å·®
          loss = torch.mean((predictions - y) ** 2) 
          #print(loss.size())
          losses.append(loss.data.numpy())
          
          # æ¯éš”10000ä¸ªå‘¨æœŸæ‰“å°ä¸€ä¸‹æŸå¤±å‡½æ•°æ•°å€¼
          if i % 10000 == 0:
              print('loss:', loss)
              
          #å¯¹æŸå¤±å‡½æ•°è¿›è¡Œæ¢¯åº¦åä¼ 
          loss.backward()
          
          #åˆ©ç”¨ä¸Šä¸€æ­¥è®¡ç®—ä¸­å¾—åˆ°çš„weightsï¼Œbiasesç­‰æ¢¯åº¦ä¿¡æ¯æ›´æ–°weightsæˆ–biasesä¸­çš„dataæ•°å€¼
          weights.data.add_(- learning_rate * weights.grad)  
          biases.data.add_(- learning_rate * biases.grad)
          weights2.data.add_(- learning_rate * weights2.grad)
          
          # æ¸…ç©ºæ‰€æœ‰å˜é‡çš„æ¢¯åº¦å€¼ã€‚
          # å› ä¸ºpytorchä¸­backwardä¸€æ¬¡æ¢¯åº¦ä¿¡æ¯ä¼šè‡ªåŠ¨ç´¯åŠ åˆ°å„ä¸ªå˜é‡ä¸Šï¼Œå› æ­¤éœ€è¦æ¸…ç©ºï¼Œå¦åˆ™ä¸‹ä¸€æ¬¡è¿­ä»£ä¼šç´¯åŠ ï¼Œé€ æˆå¾ˆå¤§çš„åå·®
          weights.grad.zero_()
          biases.grad.zero_()
          weights2.grad.zero_()
          
      loss: tensor(2256.8876, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(738.2561, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(561.8528, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(507.0011, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(473.5310, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(466.2351, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(462.0210, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(459.2573, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(457.6207, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(456.6714, dtype=torch.float64, grad_fn=<MeanBackward0>)
      ```
      
      ```python
      # æ‰“å°è¯¯å·®æ›²çº¿
      plt.plot(losses)
      plt.xlabel('Epoch')
      plt.ylabel('Loss')
      plt.show()
      ```
      
      ![](.\3-4.jpg)
      
      
      
      ç»˜åˆ¶æ·±åº¦å­¦ä¹ æ‹Ÿåˆæ›²çº¿
      
      ```python
      x_data = x.data.numpy() # è·å¾—xåŒ…è£¹çš„æ•°æ®
      plt.figure(figsize = (10, 7)) #è®¾å®šç»˜å›¾çª—å£å¤§å°
      xplot, = plt.plot(x_data, y.data.numpy(), 'o') # ç»˜åˆ¶åŸå§‹æ•°æ®
      
      yplot, = plt.plot(x_data, predictions.data.numpy())  #ç»˜åˆ¶æ‹Ÿåˆæ•°æ®
      plt.xlabel('X') #æ›´æ”¹åæ ‡è½´æ ‡æ³¨
      plt.ylabel('Y') #æ›´æ”¹åæ ‡è½´æ ‡æ³¨
      plt.legend([xplot, yplot],['Data', 'Prediction under 1000000 epochs']) #ç»˜åˆ¶å›¾ä¾‹
      plt.savefig("3-5.jpg")
      plt.show()
      ```
      
      ![](.\3-5.jpg)
      
      ä¸Šé¢çš„ç¨‹åºä¹‹æ‰€ä»¥è·‘å¾—å¾ˆæ…¢ï¼Œæ˜¯å› ä¸ºxçš„å–å€¼èŒƒå›´1ï½50ã€‚ è€Œç”±äºæ‰€æœ‰æƒé‡å’Œbiasesçš„å–å€¼èŒƒå›´è¢«è®¾å®šä¸º-1,1çš„æ­£æ€åˆ†å¸ƒéšæœºæ•°ï¼Œè¿™æ ·å°±å¯¼è‡´ æˆ‘ä»¬è¾“å…¥ç»™éšå«å±‚èŠ‚ç‚¹çš„æ•°å€¼èŒƒå›´ä¸º-50~50ï¼Œ è¦æƒ³å°†sigmoidå‡½æ•°çš„å¤šä¸ªå³°å€¼è°ƒèŠ‚åˆ°æˆ‘ä»¬æœŸæœ›çš„ä½ç½®éœ€è¦è€—è´¹å¾ˆå¤šçš„è®¡ç®—æ—¶é—´ã€‚
      
      æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå°±æ˜¯å°†è¾“å…¥å˜é‡çš„èŒƒå›´å½’ä¸€åŒ–(åªéœ€è¦æ”¹å˜è¾“å…¥å˜é‡x)
      
      ```python
      #åˆ›å»ºå½’ä¸€åŒ–çš„å˜é‡xï¼Œå®ƒçš„å–å€¼æ˜¯0.02,0.04,...,1
      x = torch.tensor(np.arange(len(counts), dtype = float) / len(counts), requires_grad = True)
      
      #è¾“å‡ºæŸå¤±å‡½æ•°ç»“æœ
      loss: tensor(2165.3436, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(940.2517, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(689.8824, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(471.5665, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(231.3214, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(123.2615, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(74.8383, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(56.6815, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(48.7930, dtype=torch.float64, grad_fn=<MeanBackward0>)
      loss: tensor(44.8804, dtype=torch.float64, grad_fn=<MeanBackward0>)
      ```
      
      ```python
      # æ‰“å°è¯¯å·®æ›²çº¿
      # semilogy()å¯¹yè½´æŒ‰å¯¹æ•°è¿›è¡Œç¼©æ”¾
      plt.semilogy(losses)
      plt.xlabel('Epoch')
      plt.ylabel('Loss')
      plt.savefig("3-6.jpg")
      plt.show()
      ```
      
      ![](.\3-6.jpg)
      
      ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿ï¼ˆä»£ç åŒä¸Šï¼‰
      
      ![](.\3-7.jpg)
      
      å¯¹æ¥ä¸‹æ¥çš„50ä¸ªæ•°æ®è¿›è¡Œé¢„æµ‹
      
      ```python
      counts_predict = rides['cnt'][50:100] #è¯»å–å¾…é¢„æµ‹çš„æ¥ä¸‹æ¥çš„50ä¸ªæ•°æ®ç‚¹
      
      #é¦–å…ˆå¯¹æ¥ä¸‹æ¥çš„50ä¸ªæ•°æ®ç‚¹è¿›è¡Œé€‰å–ï¼Œæ³¨æ„xåº”è¯¥å–51ï¼Œ52ï¼Œâ€¦â€¦ï¼Œ100ï¼Œç„¶åå†å½’ä¸€åŒ–
      x = torch.tensor((np.arange(len(counts_predict), dtype = float) + len(counts) )/ len(counts_predict)
                       , requires_grad = True)
      y=torch.tensor(np.array(counts_predict),dtype=torch.double,requires_grad=True)
      x=x.view(len(x),-1)
      hidden=x*weights+biases
      # hidden = x.expand(sz, len(x)).t() * weights.expand(len(x), sz) + biases.expand(len(x), sz)
      hidden=torch.sigmoid(hidden)
      predictions=hidden.mm(weights2)
      loss=torch.mean((y-predictions)**2)
      
      x_data=x.data.numpy()
      plt.figure(figsize=(10,7))
      xplot, =plt.plot(x_data,y.data.numpy(),'o')
      yplot, =plt.plot(x_data,predictions.data.numpy())
      plt.xlabel("X")
      plt.ylabel("y")
      plt.savefig("3-8.jpg")
      plt.show()
      ```
      
      ![](.\3-8.jpg)
      
      é¢„æµ‹å‘ç°å­˜åœ¨ç€éå¸¸ä¸¥é‡çš„è¿‡æ‹Ÿåˆç°è±¡ï¼ŒåŸå› æ˜¯xå’Œyæ ¹æœ¬æ²¡æœ‰å…³ç³»ï¼Œå³å•è½¦ä½¿ç”¨æ•°é‡ä¸ä¾èµ–äºä¸‹æ ‡ã€‚
      
   3. äººå·¥ç¥ç»ç½‘ç»œNeuï¼ˆå•è½¦é¢„æµ‹å™¨2.0ï¼‰

      1. æ•°æ®é¢„å¤„ç†

         å¯¹æ•°å€¼å˜é‡ï¼ˆè¿ç»­ï¼‰è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†

         ç”±äºæˆ‘ä»¬åˆ©ç”¨äº†å…¨éƒ¨æ•°æ®æ¥è®­ç»ƒç¥ç»ç½‘ç»œï¼Œæ‰€ä»¥é‡‡ç”¨ä¹‹å‰ä»‹ç»çš„ä¸€æ¬¡æ€§åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒç½‘ç»œçš„æ–¹æ³•å°±ä¼šå¾ˆæ…¢ï¼Œ æ‰€ä»¥æˆ‘ä»¬å°†æ•°æ®åˆ’åˆ†æˆäº†ä¸åŒçš„æ’®ï¼ˆbatchï¼‰ï¼Œä¸€ä¸ªæ‰¹æ¬¡ä¸€ä¸ªæ‰¹æ¬¡åœ°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå› æ­¤æˆ‘ä»¬è¿˜è¦å¯¹æ•°æ®è¿›è¡Œåˆ’åˆ†ã€‚

         å¯¹äºç±»å‹å˜é‡ï¼ˆç¦»æ•£ï¼‰å¤„ç†ï¼Œè½¬æ¢æˆç‹¬çƒ­ç¼–ç 

         æœ‰å¾ˆå¤šå˜é‡éƒ½å±äºç±»å‹å˜é‡ï¼Œä¾‹å¦‚season=1,2,3,4ï¼Œåˆ†å››å­£ã€‚æˆ‘ä»¬ä¸èƒ½å°†seasonå˜é‡ç›´æ¥è¾“å…¥åˆ°ç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯å› ä¸ºseasonæ•°å€¼è¶Šé«˜å¹¶ä¸è¡¨ç¤ºç›¸åº”çš„ä¿¡å·å¼ºåº¦è¶Šå¤§ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆæ˜¯å°†ç±»å‹å˜é‡ç”¨ä¸€ä¸ªâ€œä¸€ä½çƒ­ç â€œï¼ˆone-hotï¼‰æ¥ç¼–ç ï¼Œä¹Ÿå°±æ˜¯ï¼š

         ğ‘ ğ‘’ğ‘ğ‘ ğ‘œğ‘›=1â†’(1,0,0,0)

         ğ‘ ğ‘’ğ‘ğ‘ ğ‘œğ‘›=2â†’(0,1,0,0)

         ğ‘ ğ‘’ğ‘ğ‘ ğ‘œğ‘›=3â†’(0,0,1,0)

         ğ‘ ğ‘’ğ‘ğ‘ ğ‘œğ‘›=4â†’(0,0,0,1)

         å› æ­¤ï¼Œå¦‚æœä¸€ä¸ªç±»å‹å˜é‡æœ‰nä¸ªä¸åŒå–å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„â€œä¸€ä½çƒ­ç â€œæ‰€å¯¹åº”çš„å‘é‡é•¿åº¦å°±ä¸ºn

         ```python
         #å¯¹äºç±»å‹å˜é‡çš„ç‰¹æ®Šå¤„ç†
         # season=1,2,3,4, weathersi=1,2,3, mnth= 1,2,...,12, hr=0,1, ...,23, weekday=0,1,...,6
         # ç»è¿‡ä¸‹é¢çš„å¤„ç†åï¼Œå°†ä¼šå¤šå‡ºè‹¥å¹²ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œå¯¹äºseasonå˜é‡å°±ä¼šæœ‰ season_1, season_2, season_3, season_4
         # è¿™å››ç§ä¸åŒçš„ç‰¹å¾ã€‚
         dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']
         for each in dummy_fields:
             #åˆ©ç”¨pandaså¯¹è±¡ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å°†ä¸€ä¸ªç±»å‹å˜é‡å±æ€§è¿›è¡Œone-hotç¼–ç ï¼Œå˜æˆå¤šä¸ªå±æ€§
             dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)
             rides = pd.concat([rides, dummies], axis=1)
         
         # æŠŠåŸæœ‰çš„ç±»å‹å˜é‡å¯¹åº”çš„ç‰¹å¾å»æ‰ï¼Œå°†ä¸€äº›ä¸ç›¸å…³çš„ç‰¹å¾å»æ‰
         fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', 
                           'weekday', 'atemp', 'mnth', 'workingday', 'hr']
         data = rides.drop(fields_to_drop, axis=1)
         data.head()
         ```
         
         å¯¹æ•°å€¼æ•°å€¼ç±»å‹å˜é‡è¿›è¡Œæ ‡å‡†åŒ–
         
         ```python
         # è°ƒæ•´æ‰€æœ‰çš„ç‰¹å¾ï¼Œæ ‡å‡†åŒ–å¤„ç†
         quant_features = ['cnt', 'temp', 'hum', 'windspeed']
         #quant_features = ['temp', 'hum', 'windspeed']
         
         # æˆ‘ä»¬å°†æ¯ä¸€ä¸ªå˜é‡çš„å‡å€¼å’Œæ–¹å·®éƒ½å­˜å‚¨åˆ°scaled_featureså˜é‡ä¸­ã€‚
         scaled_features = {}
         for each in quant_features:
             mean, std = data[each].mean(), data[each].std()
             scaled_features[each] = [mean, std]
             data.loc[:, each] = (data[each] - mean)/std
         ```
         
         å°†æ•°æ®é›†è¿›è¡Œåˆ†å‰²ï¼Œåˆ†å‰²æˆæµ‹è¯•é›†å’Œè®­ç»ƒé›†
         
         ```python
         # å°†æ‰€æœ‰çš„æ•°æ®é›†åˆ†ä¸ºæµ‹è¯•é›†å’Œè®­ç»ƒé›†ï¼Œæˆ‘ä»¬ä»¥å21å¤©æ•°æ®ä¸€å…±21*24ä¸ªæ•°æ®ç‚¹ä½œä¸ºæµ‹è¯•é›†ï¼Œå…¶å®ƒæ˜¯è®­ç»ƒé›†
         test_data = data[-21*24:]
         train_data = data[:-21*24]
         print('è®­ç»ƒæ•°æ®ï¼š',len(train_data),'æµ‹è¯•æ•°æ®ï¼š',len(test_data))
         
         # å°†æˆ‘ä»¬çš„æ•°æ®åˆ—åˆ†ä¸ºç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—
         
         #ç›®æ ‡åˆ—
         target_fields = ['cnt', 'casual', 'registered']
         features, targets = train_data.drop(target_fields, axis=1), train_data[target_fields]
         test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]
         
         # å°†æ•°æ®ä»pandas dataframeè½¬æ¢ä¸ºnumpy
         X = features.values
         Y = targets['cnt'].values
         Y = Y.astype(float)
         Y = Y.reshape([-1])
         
         è®­ç»ƒæ•°æ®ï¼š 16875 æµ‹è¯•æ•°æ®ï¼š 504
         ```
         
      2. æ„å»ºç¥ç»ç½‘ç»œå¹¶è¿›è¡Œè®­ç»ƒ
      
         1. æ‰‹åŠ¨ç¼–å†™ç”¨Tensorè¿ç®—çš„äººå·¥ç¥ç»ç½‘ç»œ
      
            ```python
            # å®šä¹‰ç¥ç»ç½‘ç»œæ¶æ„ï¼Œfeatures.shape[1]ä¸ªè¾“å…¥å±‚å•å…ƒï¼Œ10ä¸ªéšå«å±‚ï¼Œ1ä¸ªè¾“å‡ºå±‚
            input_size = features.shape[1] #è¾“å…¥å±‚å•å…ƒä¸ªæ•°
            hidden_size = 10 #éšå«å±‚å•å…ƒä¸ªæ•°
            output_size = 1 #è¾“å‡ºå±‚å•å…ƒä¸ªæ•°
            batch_size = 128 #æ¯éš”batchçš„è®°å½•æ•°
            weights1 = torch.randn([input_size, hidden_size], dtype = torch.double,  requires_grad = True) #ç¬¬ä¸€åˆ°äºŒå±‚æƒé‡
            biases1 = torch.randn([hidden_size], dtype = torch.double, requires_grad = True) #éšå«å±‚åç½®
            weights2 = torch.randn([hidden_size, output_size], dtype = torch.double, requires_grad = True) #éšå«å±‚åˆ°è¾“å‡ºå±‚æƒé‡
            def neu(x):
                #è®¡ç®—éšå«å±‚è¾“å‡º
                #xä¸ºbatch_size * input_sizeçš„çŸ©é˜µï¼Œweights1ä¸ºinput_size*hidden_sizeçŸ©é˜µï¼Œ
                #biasesä¸ºhidden_sizeå‘é‡ï¼Œè¾“å‡ºä¸ºbatch_size * hidden_sizeçŸ©é˜µ    
                hidden = x.mm(weights1) + biases1.expand(x.size()[0], hidden_size)
                hidden = torch.sigmoid(hidden)
                
                #è¾“å…¥batch_size * hidden_sizeçŸ©é˜µï¼Œmmä¸Šweights2, hidden_size*output_sizeçŸ©é˜µï¼Œ
                #è¾“å‡ºbatch_size*output_sizeçŸ©é˜µ
                output = hidden.mm(weights2)
                return output
            def cost(x, y):
                # è®¡ç®—æŸå¤±å‡½æ•°
                error = torch.mean((x - y)**2)
                return error
            def zero_grad():
                # æ¸…ç©ºæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ä¿¡æ¯
                if weights1.grad is not None and biases1.grad is not None and weights2.grad is not None:
                    weights1.grad.data.zero_()
                    weights2.grad.data.zero_()
                    biases1.grad.data.zero_()
            def optimizer_step(learning_rate):
                # æ¢¯åº¦ä¸‹é™ç®—æ³•
                weights1.data.add_(- learning_rate * weights1.grad.data)
                weights2.data.add_(- learning_rate * weights2.grad.data)
                biases1.data.add_(- learning_rate * biases1.grad.data)
            ```
      
            ```python
            # ç¥ç»ç½‘ç»œè®­ç»ƒå¾ªç¯
            losses = []
            for i in range(1000):
                # æ¯128ä¸ªæ ·æœ¬ç‚¹è¢«åˆ’åˆ†ä¸ºä¸€ä¸ªæ’®ï¼Œåœ¨å¾ªç¯çš„æ—¶å€™ä¸€æ‰¹ä¸€æ‰¹åœ°è¯»å–
                batch_loss = []
                # startå’Œendåˆ†åˆ«æ˜¯æå–ä¸€ä¸ªbatchæ•°æ®çš„èµ·å§‹å’Œç»ˆæ­¢ä¸‹æ ‡
                for start in range(0, len(X), batch_size):
                    end = start + batch_size if start + batch_size < len(X) else len(X)
                    xx = torch.tensor(X[start:end], dtype = torch.double, requires_grad = True)
                    yy = torch.tensor(Y[start:end], dtype = torch.double, requires_grad = True)
                    predict = neu(xx)
                    loss = cost(predict, yy)
                    zero_grad()
                    loss.backward()
                    optimizer_step(0.01)
                    batch_loss.append(loss.data.numpy())
                
                # æ¯éš”100æ­¥è¾“å‡ºä¸€ä¸‹æŸå¤±å€¼ï¼ˆlossï¼‰
                if i % 100==0:
                    losses.append(np.mean(batch_loss))
                    print(i, np.mean(batch_loss))
            ```
      
            ```python
            # æ‰“å°è¾“å‡ºæŸå¤±å€¼
            fig = plt.figure(figsize=(10, 7))
            plt.plot(np.arange(len(losses))*100,losses, 'o-')
            plt.xlabel('epoch')
            plt.ylabel('MSE')
            plt.savefig("3-9.jpg")
            ```
      
            ![](.\3-9.jpg)
      
         2. è°ƒç”¨PyTorchç°æˆçš„å‡½æ•°ï¼Œæ„å»ºåºåˆ—åŒ–çš„ç¥ç»ç½‘ç»œ
      
            ```python
            # å®šä¹‰ç¥ç»ç½‘ç»œæ¶æ„ï¼Œfeatures.shape[1]ä¸ªè¾“å…¥å±‚å•å…ƒï¼Œ10ä¸ªéšå«å±‚ï¼Œ1ä¸ªè¾“å‡ºå±‚
            input_size = features.shape[1]
            hidden_size = 10
            output_size = 1
            batch_size = 128
            neu = torch.nn.Sequential(
                torch.nn.Linear(input_size, hidden_size),
                torch.nn.Sigmoid(),
                torch.nn.Linear(hidden_size, output_size),
            )
            cost = torch.nn.MSELoss()
            # # pytorchè‡ªå·±ä¼šå‡†å¤‡å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨neu.parameterså°±è¡Œ
            optimizer = torch.optim.SGD(neu.parameters(), lr = 0.01)
            
            ```
      
            ```python
            # ç¥ç»ç½‘ç»œè®­ç»ƒå¾ªç¯
            losses = []
            for i in range(1000):
                # æ¯128ä¸ªæ ·æœ¬ç‚¹è¢«åˆ’åˆ†ä¸ºä¸€ä¸ªæ’®ï¼Œåœ¨å¾ªç¯çš„æ—¶å€™ä¸€æ‰¹ä¸€æ‰¹åœ°è¯»å–
                batch_loss = []
                # startå’Œendåˆ†åˆ«æ˜¯æå–ä¸€ä¸ªbatchæ•°æ®çš„èµ·å§‹å’Œç»ˆæ­¢ä¸‹æ ‡
                for start in range(0, len(X), batch_size):
                    end = start + batch_size if start + batch_size < len(X) else len(X)
                    xx = torch.tensor(X[start:end], dtype = torch.float, requires_grad = True)
                    yy = torch.tensor(Y[start:end], dtype = torch.float, requires_grad = True)
                    predict = neu(xx)
                    loss = cost(predict, yy)
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    batch_loss.append(loss.data.numpy())
                
                # æ¯éš”100æ­¥è¾“å‡ºä¸€ä¸‹æŸå¤±å€¼ï¼ˆlossï¼‰
                if i % 100==0:
                    losses.append(np.mean(batch_loss))
                    print(i, np.mean(batch_loss))
            ```
      
            è°ƒç”¨PyTorchç°æˆå‡½æ•°ï¼Œæ”¶æ•›æ›´å¿«
         
         3. æµ‹è¯•ç¥ç»ç½‘ç»œ
         
            ```python
            # ç”¨è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
            targets = test_targets['cnt'] #è¯»å–æµ‹è¯•é›†çš„cntæ•°å€¼
            targets = targets.values.reshape([len(targets),1]) #å°†æ•°æ®è½¬æ¢æˆåˆé€‚çš„tensorå½¢å¼
            targets = targets.astype(float) #ä¿è¯æ•°æ®ä¸ºå®æ•°
            
            # å°†å±æ€§å’Œé¢„æµ‹å˜é‡åŒ…è£¹åœ¨Variableå‹å˜é‡ä¸­
            x = torch.tensor(test_features.values, dtype = torch.float, requires_grad = True)
            y = torch.tensor(targets, dtype = torch.float, requires_grad = True)
            
            # ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œé¢„æµ‹
            predict = neu(x)
            predict = predict.data.numpy()
            # å°†å21å¤©çš„é¢„æµ‹æ•°æ®ä¸çœŸå®æ•°æ®ç”»åœ¨ä¸€èµ·å¹¶æ¯”è¾ƒ
            # æ¨ªåæ ‡è½´æ˜¯ä¸åŒçš„æ—¥æœŸï¼Œçºµåæ ‡è½´æ˜¯é¢„æµ‹æˆ–è€…çœŸå®æ•°æ®çš„å€¼
            fig, ax = plt.subplots(figsize = (10, 7))
            
            mean, std = scaled_features['cnt']
            ax.plot(predict * std + mean, label='Prediction', linestyle = '--')
            ax.plot(targets * std + mean, label='Data', linestyle = '-')
            ax.legend()
            ax.set_xlabel('Date-time')
            ax.set_ylabel('Counts')
            # å¯¹æ¨ªåæ ‡è½´è¿›è¡Œæ ‡æ³¨
            dates = pd.to_datetime(rides.loc[test_data.index]['dteday'])
            # lambda d: d.strftime() dæ˜¯å‚æ•°ï¼Œd.strftime()æ˜¯è¿”å›çš„ç»“æœ
            #%b æœ¬åœ°ç®€åŒ–çš„æœˆä»½åç§° %d  æœˆå†…ä¸­çš„ä¸€å¤©ï¼ˆ0-31ï¼‰
            dates = dates.apply(lambda d: d.strftime('%b %d'))
            #set_xticksè®¾ç½®æ¨ªè½´æ ‡è®°
            #set_xticklabelsè®¾ç½®æ¨ªè½´æ ‡ç­¾
            ax.set_xticks(np.arange(len(dates))[12::24])
            ax.set_xticklabels(dates[12::24], rotation=45)
            ```
         
            ![](.\3-11.jpg)
         
         å¯ä»¥çœ‹åˆ°ï¼Œä¸¤ä¸ªæ›²çº¿åŸºæœ¬æ˜¯å»åˆçš„ ï¼Œä½†æ˜¯åœ¨12æœˆ25æ—¥å‰åå‡ å¤©çš„å®é™…å€¼å’Œé¢„æµ‹å€¼åå·®è¾ƒå¤§ã€‚ä»”ç»†è§‚å¯Ÿæ•°æ®ï¼Œæˆ‘ä»¬å‘ç°12æœˆ25æ—¥æ­£å¥½æ˜¯åœ£è¯èŠ‚ï¼Œäººä»¬çš„å‡ºè¡Œä¹ æƒ¯ä¼šä¸å¾€æ—¥æœ‰å¾ˆå¤§çš„ä¸åŒã€‚åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ ·æœ¬ä¸­ï¼Œå› ä¸ºæ•´ä¸ªæ•°æ®ä»…æœ‰ä¸¤å¹´é•¿åº¦ï¼Œæ‰€ä»¥åŒ…å«åœ£è¯èŠ‚å‰åçš„æ ·æœ¬ä»…æœ‰ä¸€æ¬¡ï¼Œè¿™å°±å¯¼è‡´æˆ‘ä»¬æ²¡åŠæ³•å¯¹è¿™ä¸€ç‰¹æ®Šå‡æœŸæ¨¡å¼è¿›è¡Œå¾ˆå¥½çš„é¢„æµ‹ã€‚
      
   4. å‰–æç¥ç»ç½‘ç»œNeu

      å¯¹ç½‘ç»œå‡ºç°çš„é—®é¢˜è¿›è¡Œè¯Šæ–­ï¼Œçœ‹çœ‹å“ªä¸€äº›ç¥ç»å…ƒå¯¼è‡´äº†é¢„æµ‹åå·®

      ```python
      # é€‰å‡ºä¸‰å¤©é¢„æµ‹ä¸å‡†çš„æ—¥æœŸï¼šDec 22ï¼Œ23ï¼Œ24
      # å°†è¿™ä¸‰å¤©çš„æ•°æ®èšé›†åˆ°ä¸€èµ·ï¼Œå­˜å…¥subsetå’Œsubtargetsä¸­
      # æ ¹æ®ridesæ¯ä¸€è¡Œ"dteday"é¡¹æ˜¯å¦ç­‰äºæ‰€ç»™æ—¥æœŸï¼Œå½¢æˆä¸€ä¸ªboolåˆ—è¡¨
      bool1 = rides['dteday'] == '2012-12-22'
      bool2 = rides['dteday'] == '2012-12-23'
      bool3 = rides['dteday'] == '2012-12-24'
      
      # zip(bool1,bool2,bool2)æ˜¯å°†bool1,bool2,bool3æ¯ié¡¹,
      # ç»„æˆ1ä¸ª3å…ƒç´ åˆ—è¡¨ï¼Œç„¶åå°†æ‰€æœ‰3å…ƒç´ åˆ—è¡¨åˆæˆä¸€ä¸ªåˆ—è¡¨
      #any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° iterable æ˜¯å¦å…¨éƒ¨ä¸º Falseï¼Œåˆ™è¿”å› Falseï¼Œ
      # å¦‚æœæœ‰ä¸€ä¸ªä¸º Trueï¼Œåˆ™è¿”å› Trueã€‚å…ƒç´ é™¤äº†æ˜¯ 0ã€ç©ºã€FALSE å¤–éƒ½ç®— TRUEã€‚
      bools = [any(tup) for tup in zip(bool1,bool2,bool3) ]
      # å°†ç›¸åº”çš„å˜é‡å–å‡ºæ¥
      # test_featureså’Œtest_targetsçš„ç´¢å¼•å¹¶ä¸æ˜¯ä»0å¼€å§‹ï¼Œè€Œæ˜¯ä»æˆªå–çš„åœ°æ–¹å¼€å§‹ï¼Œæ‰€ä»¥èƒ½ç”¨locç¡®å®š
      # print(test_features.index)
      subset = test_features.loc[rides[bools].index]
      # print(subset)
      subtargets = test_targets.loc[rides[bools].index]
      # print(subtargets)
      subtargets = subtargets['cnt']
      subtargets = subtargets.values.reshape([len(subtargets),1])
      ```

      ```python
      def feature(X, net):
          # å®šä¹‰äº†ä¸€ä¸ªå‡½æ•°å¯ä»¥æå–ç½‘ç»œçš„æƒé‡ä¿¡æ¯ï¼Œæ‰€æœ‰çš„ç½‘ç»œå‚æ•°ä¿¡æ¯å…¨éƒ¨å­˜å‚¨åœ¨äº†neuçš„named_parametersé›†åˆä¸­äº†
          X = torch.tensor(X, dtype = torch.float, requires_grad = False)
          dic = dict(net.named_parameters()) #æå–å‡ºæ¥è¿™ä¸ªé›†åˆ
          weights = dic['0.weight'] #å¯ä»¥æŒ‰ç…§å±‚æ•°.åç§°æ¥ç´¢å¼•é›†åˆä¸­çš„ç›¸åº”å‚æ•°å€¼
          biases = dic['0.bias'] #å¯ä»¥æŒ‰ç…§å±‚æ•°.åç§°æ¥ç´¢å¼•é›†åˆä¸­çš„ç›¸åº”å‚æ•°å€¼
          h = torch.sigmoid(X.mm(weights.t()) + biases.expand([len(X), len(biases)])) # éšå«å±‚çš„è®¡ç®—è¿‡ç¨‹
          return h # è¿”å›éšè—å±‚çš„è®¡ç®—
      
      # å°†è¿™å‡ å¤©çš„æ•°æ®è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œè¯»å–å‡ºéšå«å±‚ç¥ç»å…ƒçš„æ¿€æ´»æ•°å€¼ï¼Œå­˜å…¥resultsä¸­
      # resultséšè—å±‚è¾“å‡ºæ•°æ®
      results = feature(subset.values, neu).data.numpy()
      # è¿™äº›æ•°æ®å¯¹åº”çš„é¢„æµ‹å€¼ï¼ˆè¾“å‡ºå±‚ï¼‰
      #predictè¾“å‡ºå±‚è¾“å‡ºæ•°æ®
      predict = neu(torch.tensor(subset.values, dtype = torch.float, requires_grad = True)).data.numpy()
      
      #å°†é¢„æµ‹å€¼è¿˜åŸæˆåŸå§‹æ•°æ®çš„æ•°å€¼èŒƒå›´
      mean, std = scaled_features['cnt']
      predict = predict * std + mean
      subtargets = subtargets * std + mean
      # å°†æ‰€æœ‰çš„ç¥ç»å…ƒæ¿€æ´»æ°´å¹³ç”»åœ¨åŒä¸€å¼ å›¾ä¸Šï¼Œè“è‰²çš„æ˜¯æ¨¡å‹é¢„æµ‹çš„æ•°å€¼
      fig, ax = plt.subplots(figsize = (8, 6))
      # resultsæ¯ä¸€åˆ—å…ƒç´ æ˜¯è¾“å…¥çš„åŒä¸€è¡Œå…ƒç´ çš„å„ä¸ªç¥ç»å…ƒè¾“å‡ºï¼Œæ¯è¡Œæ˜¯ridesæ¯ä¸€è¡Œæ•°æ®
      # .ç‚¹ :è™šçº¿ï¼Œalphaé€æ˜åº¦
      ax.plot(results[:,:],'.:',alpha = 0.3)
      # bè“è‰² sæ­£æ–¹å½¢ -çº¿ ï¼Œcnté¢„æµ‹å€¼ï¼Œ
      ax.plot((predict - min(predict)) / (max(predict) - min(predict)),'bs-',label='Prediction')
      # rçº¢è‰² oåœ†åœˆ -çº¿,cntå®é™…æƒ…å†µ
      ax.plot((subtargets - min(predict)) / (max(predict) - min(predict)),'ro-',label='Real')
      #:è™šçº¿ *äº”è§’æ˜Ÿ éšè—å±‚ç¬¬4ä¸ªç¥ç»å…ƒè¾“å‡ºå€¼
      ax.plot(results[:, 3],':*',alpha=1, label='Neuro 4')
      
      # set_xlimè®¾ç½®æ¨ªè½´èŒƒå›´
      ax.set_xlim(right=len(predict))
      # æ˜¾ç¤ºæ ‡ç­¾
      ax.legend()
      plt.ylabel('Normalized Values')
      
      dates = pd.to_datetime(rides.loc[subset.index]['dteday'])
      dates = dates.apply(lambda d: d.strftime('%b %d'))
      # set_xticksè®¾ç½®åæ ‡è½´åˆ»åº¦
      ax.set_xticks(np.arange(len(dates))[12::24])
      # set_xticklabelsè®¾ç½®åˆ»åº¦çš„æ˜¾ç¤ºæ–‡æœ¬
      ax.set_xticklabels(dates[12::24], rotation=45)
      fig.savefig("3-12.jpg")
      ```

      ![]()

4. æœºå™¨ä¹Ÿæ‡‚å¾—æ„Ÿæƒ…-ä¸­æ–‡æƒ…ç»ªåˆ†ç±»å™¨

5. æ‰‹å†™æ•°å­—è¯†åˆ«-è®¤è¯†å·ç§¯ç¥ç»ç½‘ç»œ-è®¤è¯†å·ç§¯ç¥ç»ç½‘ç»œ

6. æ‰‹å†™æ•°å­—åŠ æ³•æœº-è¿ç§»å­¦ä¹ 

7. ä½ è‡ªå·±çš„Prisma-å›¾åƒé£æ ¼è¿ç§»

8. äººå·¥æ™ºèƒ½é€ å‡æœ¯--å›¾åƒç”Ÿæˆä¸å¯¹æŠ—å­¦ä¹ 

9. è¯æ±‡æ˜Ÿç©º--ç¥ç»è¯­è¨€æ¨¡å‹ä¸Word2Vec

10. LSTMä½œæ›²æœº-åºåˆ—ç”Ÿæˆæ¨¡å‹

11. ç¥ç»ç¿»è¯‘æœº--ç«¯åˆ°ç«¯æœºå™¨ç¿»è¯‘

12. AIæ¸¸æˆé«˜æ‰‹--æ·±åº¦å¼ºåŒ–å­¦ä¹ 

